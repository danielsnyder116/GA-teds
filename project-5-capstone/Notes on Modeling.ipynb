{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary - For NON-TECHNICAL Stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We first started by using the total score, the aggregation of four integer scores and the fifth essay discrete integer scores (460,480,500,...)\n",
    "\n",
    "    Baseline is .42.7% predictive accuracy \n",
    "\n",
    "2. We then put it into a bunch of models...\n",
    "    - Random Forest Classifier: oob score of .35 - that's worse than guessing :(\n",
    "        -you can tune this by doing recursive feature elimination\n",
    "            - when we did this, it told us to just keep the one variable of per_person_avr_income\n",
    "            - however, it did not greatly improve the model's accuracy. \n",
    "        \n",
    "        \n",
    "    - KNN: knn.score of .48 - so improved, but only marginally \n",
    "    \n",
    "    - Logistic Regression Classification: predict probability average score of .43 - but without tuning and improvement\n",
    "        -sticking with this - a lot quicker, and able to tweak easily \n",
    "        \n",
    "        -After tweaking to use combined score, kfold validation, and for some reason binary (no multi_class), up to .5804\n",
    "        -Now looking to change up the x variables being used.\n",
    "             -NEXT: Use Recursive Feature Elimination and see if useful\n",
    "             - Look into again using MAE somehow? \n",
    "    \n",
    "    - Bagged Decision Tree:Tried to do better thinking it would decrease oob score, but to no avail: oob = .35\n",
    "\n",
    "make up on error metric - MAE - close counts - average wrongness - predicted 7 vs. 8\n",
    "So what does this mean?\n",
    "\n",
    "12 minute limit\n",
    "\n",
    "Measured how close you were within \n",
    "regress y vs binary variable\n",
    "F test - would equate to two sample t test \n",
    "\n",
    "Students who got 0 on the exam,. \n",
    "\n",
    "\n",
    "Perhaps using the combined score excluding essay score would help? \n",
    "\n",
    ".between issue - mention 1901 vs 1901.0\n",
    "advice on divying up the data: by \n",
    "entertaining and educational presentation\n",
    "Challenges & Next Steps - \n",
    "\n",
    "So we went back and ran the same models using the combined score.\n",
    "3. Models with Combined Score rather than Total Score\n",
    "\n",
    "\n",
    "4. Possibly going back and trying linear regression? \n",
    "\n",
    "4. Interpretation\n",
    "\n",
    "- Based on current knowledge, there is no model very accurate on predicting student scores based on \n",
    "    the given factors. This could be good, implying that factors such as income, ethnicity, and age don't\n",
    "    significantly affect scores, which would be the overall goal (the biggest factor being intelligence).\n",
    "    \n",
    "- Could we make an assumption of normal distribution of scores and then do hypothesis tests of individual factors on whether \n",
    "    the means between two groups are significantly different? \n",
    "    \n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_The most common solution for classification models is \"one-vs-all\" (also known as \"one-vs-rest\"): Decompose the problem into multiple binary classification problems.\n",
    "Multinomial logistic regression, on the other hand, can solve this as a single problem, but how this works is beyond the scope of this lesson._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't automatically learn feature interactions.\n",
    "Feature interaction - when one x variable predicts y variable differently than the way another x variable predicts.\n",
    "Two groups, one gets better with more medicine, one gets worse with more medicine.\n",
    "Tree-based methods can detect this, but logit model can't catch this - called an Interaction  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To Do List\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Modeling\n",
    "    - RFE on x variables\n",
    "    - MAE\n",
    "    -\n",
    "2. Clean up scores and explain what is going on - will go into EDA\n",
    "\n",
    "3. If time do some hypothesis testing in EDA \n",
    "\n",
    "4. Work on Presentation \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
